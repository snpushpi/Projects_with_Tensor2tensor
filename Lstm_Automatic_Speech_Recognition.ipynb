{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lstm_Automatic_Speech_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlqq76CnoZfYCC6dKiTeXi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snpushpi/Projects_with_Tensor2tensor/blob/master/Lstm_Automatic_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxDC6eCu3A5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "706c2ff5-5b4b-42a7-b1ae-7de8463b408b"
      },
      "source": [
        "!pip install -q -U tensor2tensor\n",
        "!pip install -q tensorflow matplotlib\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install tensor2tensor==1.11.0\n",
        "!pip install tensorflow-probability==0.7.0\n",
        "!pip install pydub\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y ffmpeg\n",
        "!apt-get -qq install -y sox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "Collecting tensorflow==1.14.0\n",
            "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.1.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (0.7.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.14.0) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==1.14.0) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.14.0) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.14.0) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow-addons 0.7.1 has requirement tensorflow>=2.1.0, but you'll have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting tensor2tensor==1.11.0\n",
            "  Using cached https://files.pythonhosted.org/packages/ea/a9/c10b5283edbea85f4eb5a99d58a9edb43e764075dbc3fb50cae979ade845/tensor2tensor-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (2.23.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.1.1)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (19.9.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (4.1.3)\n",
            "Requirement already satisfied: mesh-tensorflow in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (0.1.16)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.0.2.dev201907170105)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.7.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (4.28.1)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (0.98)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.1.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (0.10.11)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (0.7.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (2.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python2.7/dist-packages (from tensor2tensor==1.11.0) (1.2.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->tensor2tensor==1.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->tensor2tensor==1.11.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->tensor2tensor==1.11.0) (2019.6.16)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->tensor2tensor==1.11.0) (2.8)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python2.7/dist-packages (from flask->tensor2tensor==1.11.0) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python2.7/dist-packages (from flask->tensor2tensor==1.11.0) (0.15.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python2.7/dist-packages (from flask->tensor2tensor==1.11.0) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python2.7/dist-packages (from flask->tensor2tensor==1.11.0) (2.10.1)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client->tensor2tensor==1.11.0) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client->tensor2tensor==1.11.0) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client->tensor2tensor==1.11.0) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client->tensor2tensor==1.11.0) (0.2.5)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python2.7/dist-packages (from mesh-tensorflow->tensor2tensor==1.11.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python2.7/dist-packages (from mesh-tensorflow->tensor2tensor==1.11.0) (0.7.1)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (1.1.6)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (1.11.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (2.2.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (0.3.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (0.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (1.1.0)\n",
            "Requirement already satisfied: functools32 in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (3.2.3.post2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (19.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (3.8.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (5.4.8)\n",
            "Requirement already satisfied: futures in /usr/local/lib/python2.7/dist-packages (from tfds-nightly->tensor2tensor==1.11.0) (3.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client->tensor2tensor==1.11.0) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client->tensor2tensor==1.11.0) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client->tensor2tensor==1.11.0) (3.0.0)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python2.7/dist-packages (from gevent->tensor2tensor==1.11.0) (0.4.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python2.7/dist-packages (from sympy->tensor2tensor==1.11.0) (1.1.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python2.7/dist-packages (from gym->tensor2tensor==1.11.0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability->tensor2tensor==1.11.0) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability->tensor2tensor==1.11.0) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python2.7/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor==1.11.0) (1.1.1)\n",
            "Requirement already satisfied: typing>=3.6.4; python_version < \"3.5\" in /usr/local/lib/python2.7/dist-packages (from promise->tfds-nightly->tensor2tensor==1.11.0) (3.7.4)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python2.7/dist-packages (from tensorflow-metadata->tfds-nightly->tensor2tensor==1.11.0) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tfds-nightly->tensor2tensor==1.11.0) (44.1.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client->tensor2tensor==1.11.0) (3.1.1)\n",
            "Installing collected packages: tensor2tensor\n",
            "  Found existing installation: tensor2tensor 1.15.7\n",
            "    Uninstalling tensor2tensor-1.15.7:\n",
            "      Successfully uninstalled tensor2tensor-1.15.7\n",
            "Successfully installed tensor2tensor-1.11.0\n",
            "Requirement already satisfied: tensorflow-probability==0.7.0 in /usr/local/lib/python2.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability==0.7.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow-probability==0.7.0) (1.16.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python2.7/dist-packages (0.24.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gGCI18QOk2b",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ORT1VYv0vG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f9b51c3-d58c-4962-b84a-3bb87bfe900e"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules: # Colab-only TensorFlow version selector\n",
        "  %tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "import base64\n",
        "import cStringIO\n",
        "import pydub\n",
        "import shutil\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import IPython\n",
        "import google.colab\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "\n",
        "# Enable TF Eager execution\n",
        "tfe = tf.contrib.eager\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "# Other setup\n",
        "Modes = tf.estimator.ModeKeys\n",
        "\n",
        "# Setup some directories\n",
        "data_dir = os.path.expanduser(\"~/t2t/data\")\n",
        "tmp_dir = os.path.expanduser(\"~/t2t/tmp\")\n",
        "train_dir = os.path.expanduser(\"~/t2t/train\")\n",
        "tf.gfile.MakeDirs(data_dir)\n",
        "tf.gfile.MakeDirs(tmp_dir)\n",
        "tf.gfile.MakeDirs(train_dir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0728 16:29:09.052959 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0728 16:29:10.486263 139747548997504 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0728 16:29:12.297512 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0728 16:29:12.298140 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0728 16:29:12.319161 139747548997504 deprecation_wrapper.py:119] From /tensorflow-1.15.2/python2.7/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "W0728 16:29:12.319828 139747548997504 deprecation_wrapper.py:119] From /tensorflow-1.15.2/python2.7/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "W0728 16:29:12.418497 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:105: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
            "\n",
            "/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/video_generated.py:34: UserWarning: \n",
            "This call to matplotlib.use() has no effect because the backend has already\n",
            "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
            "or matplotlib.backends is imported for the first time.\n",
            "\n",
            "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
            "    \"__main__\", fname, loader, pkg_name)\n",
            "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
            "    exec code in run_globals\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n",
            "    handler_func(fd_obj, events)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
            "    self.events.trigger('post_run_cell')\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/google/colab/_event_manager.py\", line 28, in trigger\n",
            "    func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
            "    activate_matplotlib(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n",
            "    matplotlib.pyplot.switch_backend(backend)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
            "    matplotlib.use(newbackend, warn=False, force=True)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1422, in use\n",
            "    reload(sys.modules['matplotlib.backends'])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
            "    line for line in traceback.format_stack()\n",
            "\n",
            "\n",
            "  matplotlib.use(\"agg\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfuJZ9fT2i4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "2b8b8862-bb41-426a-d77d-5e77cfa92e0d"
      },
      "source": [
        "problem_name = \"librispeech_clean\"\n",
        "asr_problem = problems.problem(problem_name)\n",
        "encoders = asr_problem.feature_encoders(None) \n",
        "\n",
        "model_name = \"lstm_seq2seq\"\n",
        "hparams_set = \"lstm_asr_v1\"\n",
        "t2t_problem = problems.problem(problem_name)\n",
        "t2t_problem.generate_data(data_dir, tmp_dir)\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 16:29:20.785892 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:129: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0728 16:29:20.794538 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:163: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0728 16:29:20.796180 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:225: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0728 16:29:20.797192 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:231: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0728 16:29:20.798182 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:233: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0728 16:29:36.307993 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.py:241: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100% completed\n",
            "100% completed\n",
            "100% completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IOError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3399c5aa6564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mhparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lstm_asr_v1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mt2t_problem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mt2t_problem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/librispeech.pyc\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(self, data_dir, tmp_dir, task_id)\u001b[0m\n\u001b[1;32m    177\u001b[0m       generator_utils.generate_dataset_and_shuffle(\n\u001b[1;32m    178\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_DATASETS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m           self.generator(data_dir, tmp_dir, self.DEV_DATASETS), dev_paths)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.pyc\u001b[0m in \u001b[0;36mgenerate_dataset_and_shuffle\u001b[0;34m(train_gen, train_paths, dev_gen, dev_paths, shuffle)\u001b[0m\n\u001b[1;32m    488\u001b[0m                                  \u001b[0mdev_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                                  shuffle=True):\n\u001b[0;32m--> 490\u001b[0;31m   \u001b[0mgenerate_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m   \u001b[0mgenerate_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0mmlperf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlperf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPUT_ORDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/generator_utils.pyc\u001b[0m in \u001b[0;36mgenerate_files\u001b[0;34m(generator, output_filenames, max_cases, cycle_every_n)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mwriters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/librispeech.pyc\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mmembers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mcorpus_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0mraw_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LibriSpeech\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m                 \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;31m# Reverse sort directories.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path)\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mbltn_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2235\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2236\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/tarfile.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIOError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlPG1fbrDBiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps = 300000 # Total number of train steps for all Epochs\n",
        "eval_steps = 100 # Number of steps to perform for each evaluation\n",
        "batch_size = 20\n",
        "save_checkpoints_steps = 1000\n",
        "ALPHA = 0.2\n",
        "schedule = \"continuous_train_and_eval\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH3UZMlSSeJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = trainer_lib.create_hparams(hparams_set,data_dir=data_dir, problem_name=problem_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwOFOzh5bJAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams.batch_size = 20"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S25Sc9lSbNAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams.learning_rate = 0.2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RZJvOciaFLp",
        "colab_type": "text"
      },
      "source": [
        "Model Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko1yLPYLDRFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "4755f700-3282-4e4e-cc24-2aa8e394d090"
      },
      "source": [
        "RUN_CONFIG = trainer_lib.create_run_config(\n",
        "      model_dir=train_dir,\n",
        "      model_name=model_name,\n",
        "      save_checkpoints_steps= save_checkpoints_steps\n",
        ")\n",
        "\n",
        "tensorflow_exp_fn = trainer_lib.create_experiment(\n",
        "        run_config=RUN_CONFIG,\n",
        "        hparams=hparams,\n",
        "        model_name=model_name,\n",
        "        problem_name=problem_name,\n",
        "        data_dir=data_dir, \n",
        "        train_steps=train_steps, \n",
        "        eval_steps=eval_steps, \n",
        "        #use_xla=True # For acceleration\n",
        "        use_tpu = True\n",
        "    ) \n",
        "\n",
        "tensorflow_exp_fn.train_and_evaluate()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 16:10:04.360632 139905117202304 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0d6c47954414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0meval_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#use_xla=True # For acceleration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0muse_tpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     ) \n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.pyc\u001b[0m in \u001b[0;36mcreate_experiment\u001b[0;34m(run_config, hparams, model_name, problem_name, data_dir, train_steps, eval_steps, min_eval_frequency, eval_throttle_seconds, schedule, export, decode_hparams, use_tfdbg, use_dbgprofile, eval_early_stopping_steps, eval_early_stopping_metric, eval_early_stopping_metric_delta, eval_early_stopping_metric_minimize, eval_timeout_mins, use_tpu, use_tpu_estimator, use_xla, additional_train_hooks, additional_eval_hooks, warm_start_from, decode_from_file, decode_to_file, decode_reference, std_server_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m   \u001b[0;34m\"\"\"Create Experiment.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m   \u001b[0;31m# HParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m   \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_dir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m   \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m   \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/training/python/training/hparam.pyc\u001b[0m in \u001b[0;36madd_hparam\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;31m# hyperparameter name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hyperparameter name is reserved: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Hyperparameter name is reserved: model_dir"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_73bKSuHNdzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_path = tf.train.latest_checkpoint(os.path.join(train_dir))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RHbLl_2eaC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdIrOFs5eX5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e4395960-df11-4617-dd9e-402f2b251a42"
      },
      "source": [
        "asr_model = registry.model(model_name)(hparams, Modes.PREDICT)\n",
        "\n",
        "def encode(x):\n",
        "  waveforms = encoders[\"waveforms\"].encode(x)\n",
        "  encoded_dict = asr_problem.preprocess_example({\"waveforms\":waveforms, \"targets\":[]}, Modes.PREDICT, hparams)\n",
        "  \n",
        "  return {\"inputs\" : tf.expand_dims(encoded_dict[\"inputs\"], 0), \"targets\" : tf.expand_dims(encoded_dict[\"targets\"], 0)}\n",
        "\n",
        "def decode(integers):\n",
        "  integers = list(np.squeeze(integers))\n",
        "  if 1 in integers:\n",
        "    integers = integers[:integers.index(1)]\n",
        "  return encoders[\"targets\"].decode(np.squeeze(integers))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 17:54:51.334754 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:75: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0728 17:54:51.747086 139747548997504 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:167: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCNa5Y8Q2ukP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Restore and transcribe!\n",
        "def transcribe(inputs):\n",
        "  encoded_inputs = encode(inputs)\n",
        "  with tfe.restore_variables_on_create(ckpt_path): \n",
        "    model_output = asr_model.infer(encoded_inputs, beam_size=2, alpha=0.6, decode_length=1)[\"outputs\"]\n",
        "  return decode(model_output)\n",
        "\n",
        "def play_and_transcribe(inputs):\n",
        "  waveforms = encoders[\"waveforms\"].encode(inputs)\n",
        "  IPython.display.display(IPython.display.Audio(data=waveforms, rate=16000))\n",
        "  return transcribe(inputs) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDbDIupjkr9f",
        "colab_type": "text"
      },
      "source": [
        "Record your own voice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ju4XeB02wca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Records webm file and converts\n",
        "def RecordNewAudioSample(filename=None, webm_filename=None):\n",
        "  \"\"\"Args:\n",
        "          filename - string, path for storing wav file\n",
        "          webm_filename - string, path for storing webm file\n",
        "     Returns:\n",
        "          string - path where wav file was saved. (=filename if specified)\n",
        "    \n",
        "  \"\"\"\n",
        "  # Create default filenames in tmp_dir if not specified.\n",
        "  if not filename:\n",
        "    filename = os.path.join(tmp_dir, \"recording.wav\")\n",
        "  if not webm_filename:\n",
        "    webm_filename = os.path.join(tmp_dir, \"recording.webm\")\n",
        "    \n",
        "  # Record webm file form colab.\n",
        "  \n",
        "  audio = google.colab._message.blocking_request('user_media', {\"audio\":True, \"video\":False, \"duration\":-1}, timeout_sec=600)\n",
        "  #audio = frontend.RecordMedia(True, False)\n",
        "  \n",
        "  # Convert the recording into in_memory file.\n",
        "  music_mem_file = cStringIO.StringIO(\n",
        "      base64.decodestring(audio[audio.index(',')+1:]))\n",
        "  \n",
        "  # Store webm recording in webm_filename. Storing is necessary for conversion.\n",
        "  with open(webm_filename, 'w') as fd:\n",
        "    music_mem_file.seek(0)\n",
        "    shutil.copyfileobj(music_mem_file, fd)\n",
        "    \n",
        "  # Open stored file and save it as wav with sample_rate=16000.\n",
        "  pydub.AudioSegment.from_file(webm_filename, codec=\"opus\"\n",
        "                              ).set_frame_rate(16000).export(out_f=filename,\n",
        "                                                             format=\"wav\")\n",
        "  return filename"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax4OSpJO5vUs",
        "colab_type": "text"
      },
      "source": [
        "Talk here talk here ! Click the cell next to this text :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFxy4Pkc22Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "9b3f712b-ae0c-4ef8-c7f8-18d34b85063f"
      },
      "source": [
        "# Record the sample\n",
        "my_sample_filename = RecordNewAudioSample()\n",
        "print my_sample_filename"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IOError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-75fef39e38d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Record the sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_sample_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecordNewAudioSample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmy_sample_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-91922d88a6c5>\u001b[0m in \u001b[0;36mRecordNewAudioSample\u001b[0;34m(filename, webm_filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwebm_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmusic_mem_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_mem_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m# Open stored file and save it as wav with sample_rate=16000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/shutil.pyc\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIOError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAxfYA6E539s",
        "colab_type": "text"
      },
      "source": [
        "Now Click it and see what you said :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9K2xJvO3T20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print play_and_transcribe(my_sample_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipFiIFcNkz4O",
        "colab_type": "text"
      },
      "source": [
        "Upload pre-recorded samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P43-QKJTkxrp",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "eb2b5ec9-05fd-4a5e-ebc7-3d2d1e234430"
      },
      "source": [
        "uploaded = google.colab.files.upload()\n",
        "prerecorded_messages = []\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  mem_file = cStringIO.StringIO(uploaded[fn])\n",
        "    \n",
        "  save_filename = os.path.join(tmp_dir, fn)\n",
        "  with open(save_filename, 'w') as fd:\n",
        "    mem_file.seek(0)\n",
        "    shutil.copyfileobj(mem_file, fd)\n",
        "  prerecorded_messages.append(save_filename)\n",
        "         \n",
        "              \n",
        "for inputs in prerecorded_messages:\n",
        "  outputs = play_and_transcribe(inputs)\n",
        "\n",
        "  print(\"Inputs: %s\" % inputs)\n",
        "  print(\"Outputs: %s\" % outputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fafac39c-8123-4c79-a7a0-5a5d370a3ce0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fafac39c-8123-4c79-a7a0-5a5d370a3ce0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving voice7.wav to voice7.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IOError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-26a634f8604f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprerecorded_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/files.pyc\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m           filename=filename, local_filename=local_filename))\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ab'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIOError\u001b[0m: [Errno 28] No space left on device"
          ]
        }
      ]
    }
  ]
}